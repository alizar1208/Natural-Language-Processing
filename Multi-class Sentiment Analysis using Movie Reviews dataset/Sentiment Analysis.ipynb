{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhZ-SKnmSUR-",
        "colab_type": "code",
        "outputId": "5244e7d9-dcc7-47a5-91c0-15175b8daa0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import nltk \n",
        "import random \n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords') \n",
        "nltk.download('wordnet') \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzgCW0E6SZQe",
        "colab_type": "code",
        "outputId": "2c062fc6-09ba-4938-b7b8-2cdd6287f2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# Imported the necessary libraries\n",
        "import csv\n",
        "import urllib.request as urllib2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "# Importing data using url\n",
        "url = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "\n",
        "# reading data using pandas and converting into dataframe\n",
        "df = pd.read_csv(url,delimiter='\\t',encoding='utf-8')\n",
        "df.head(10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDU5qDu_Sbj2",
        "colab_type": "code",
        "outputId": "29be7214-41ea-43f6-82ec-122861a29e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92540</td>\n",
              "      <td>4819</td>\n",
              "      <td>7th</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110754</td>\n",
              "      <td>5867</td>\n",
              "      <td>do its characters</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146918</td>\n",
              "      <td>7995</td>\n",
              "      <td>crap is what I was expecting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>126580</td>\n",
              "      <td>6805</td>\n",
              "      <td>program run</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44390</td>\n",
              "      <td>2151</td>\n",
              "      <td>a lot of their time -LRB- including mine -RRB-...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0     92540  ...          2\n",
              "1    110754  ...          2\n",
              "2    146918  ...          1\n",
              "3    126580  ...          2\n",
              "4     44390  ...          3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_zz_r53nKAg",
        "colab_type": "code",
        "outputId": "c662c82c-5ee3-4408-b129-0260b7f47c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "fullSentences = []\n",
        "curSentence = 0\n",
        "for i in range(df.shape[0]):\n",
        "  if df['SentenceId'][i]> curSentence:\n",
        "    fullSentences.append((df['Phrase'][i], df['Sentiment'][i]))\n",
        "    curSentence = curSentence +1\n",
        "fullSentDf = pd.DataFrame(fullSentences,columns=['Phrase', 'Sentiment'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92540</td>\n",
              "      <td>4819</td>\n",
              "      <td>7th</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110754</td>\n",
              "      <td>5867</td>\n",
              "      <td>do its characters</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146918</td>\n",
              "      <td>7995</td>\n",
              "      <td>crap is what I was expecting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>126580</td>\n",
              "      <td>6805</td>\n",
              "      <td>program run</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>44390</td>\n",
              "      <td>2151</td>\n",
              "      <td>a lot of their time -LRB- including mine -RRB-...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0     92540  ...          2\n",
              "1    110754  ...          2\n",
              "2    146918  ...          1\n",
              "3    126580  ...          2\n",
              "4     44390  ...          3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09uWbN4SfNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df ['Phrase'], df ['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents=[]\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  documents.append([list(word_tokenize(X_train[i])), Y_train[i]]) \n",
        "\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  documents.append([list(word_tokenize(X_test[i])), Y_test[i]]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ccNGN3WvQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "porter = PorterStemmer() \n",
        "lancaster=LancasterStemmer() \n",
        "wordnet_lemmatizer = WordNetLemmatizer() \n",
        "stopwords_en = stopwords.words(\"english\") \n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome \n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wibkp1lHWxuf",
        "colab_type": "code",
        "outputId": "b277fd3c-51c2-4c14-f76e-7d260333375d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for l in range(len(documents)):                    \n",
        "  label = documents[l][1]                          \n",
        "  tmpReview = []                                   \n",
        "  for w in documents[l][0]:                        \n",
        "    newWord = w                                    \n",
        "    if remove_stopwords and (w in stopwords_en):   \n",
        "      continue                                     \n",
        "    if removePuncs and (w in punctuations):        \n",
        "      continue                                     \n",
        "    if useStemming:\n",
        "      newWord = lancaster.stem(newWord)  \n",
        "    if useLemma: \n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord) \n",
        "    tmpReview.append(newWord)                      \n",
        "  documents[l] = (tmpReview, label)              \n",
        "  documents[l] = (' '.join(tmpReview), label) \n",
        "\n",
        "print(documents[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('While filmmaking may bit disjointed', 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InPVUfgzWztX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(documents, columns=['text', 'sentiment']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSoEouQN83iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],  df['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gaF2YPvUH7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2000,ngram_range=(1, 2)) \n",
        "# X = vectorizer.fit_transform(df[\"text\"]) \n",
        "# Y = df['sentiment'] \n",
        " \n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezvrFic8Uqyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx8g8sDt2IbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBxQFt--fHT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wjvo2WNu6k5f",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ToySXMU87V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "#1st convolutional layer\n",
        "model.add(Conv1D(filters=64, kernel_size=3,activation='relu',input_shape=(2000,1)))\n",
        "#another convlutional layer\n",
        "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
        "#maxpooling layer\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "#flatten layer\n",
        "model.add(Flatten())\n",
        "#dense layer\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3I6AgtgMaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.adam(),\n",
        "              metrics=['accuracy',f1_m,precision_m, recall_m])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXqFVIQiS-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sDSZ7J2ViP8",
        "colab_type": "code",
        "outputId": "4c5ff8cd-3b0c-4e90-8dcb-1d1333cd25f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=64,\n",
        "          epochs=10)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 56s 513us/step - loss: 1.0898 - acc: 0.5746 - f1_m: 0.5116 - precision_m: 0.6381 - recall_m: 0.4311\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 55s 507us/step - loss: 0.9997 - acc: 0.6055 - f1_m: 0.5668 - precision_m: 0.6666 - recall_m: 0.4944\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 55s 505us/step - loss: 0.9746 - acc: 0.6160 - f1_m: 0.5818 - precision_m: 0.6725 - recall_m: 0.5140\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 55s 505us/step - loss: 0.9584 - acc: 0.6214 - f1_m: 0.5901 - precision_m: 0.6763 - recall_m: 0.5245\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 55s 501us/step - loss: 0.9471 - acc: 0.6247 - f1_m: 0.5950 - precision_m: 0.6775 - recall_m: 0.5317\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 54s 496us/step - loss: 0.9365 - acc: 0.6290 - f1_m: 0.6005 - precision_m: 0.6807 - recall_m: 0.5383\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 54s 495us/step - loss: 0.9280 - acc: 0.6326 - f1_m: 0.6054 - precision_m: 0.6834 - recall_m: 0.5446\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 54s 495us/step - loss: 0.9202 - acc: 0.6351 - f1_m: 0.6085 - precision_m: 0.6841 - recall_m: 0.5489\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 54s 495us/step - loss: 0.9116 - acc: 0.6390 - f1_m: 0.6127 - precision_m: 0.6873 - recall_m: 0.5538\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 54s 496us/step - loss: 0.9056 - acc: 0.6408 - f1_m: 0.6156 - precision_m: 0.6884 - recall_m: 0.5578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_IGUrsPyP6c",
        "colab_type": "code",
        "outputId": "9fb5219a-6720-4d9f-fca7-04f43dd3eb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score,precision_score,recall_score, f1_score\n",
        "from keras.utils import to_categorical\n",
        "output=model.predict_classes(X_test,verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(\"f1 score:\",score[2])\n",
        "print(\"Precision:\",score[3])\n",
        "print(\"Recall:\",score[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.0417375199700762\n",
            "Test accuracy: 0.602567388611218\n",
            "f1 score: 0.5753365763560115\n",
            "Precision: 0.6488379226439155\n",
            "Recall: 0.5184971592122688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2wQsBdC47iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"1103258_1dconv_reg.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}